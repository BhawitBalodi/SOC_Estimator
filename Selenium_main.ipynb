{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ab042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac55f79",
   "metadata": {},
   "source": [
    "# Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'')\n",
    "para = driver.find_element(By.XPATH, '')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "# with open('D:/AI4bharat/intern/data/hindi_fileX.json', 'w', encoding='utf-8') as json_file:\n",
    "#     json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "\n",
    "print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66683665",
   "metadata": {},
   "source": [
    "# Page - 1\n",
    "# for this url - https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/populer-topics/%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19%20%E0%A4%94%E0%A4%B0%20%E0%A4%8F%E0%A4%AB%E0%A4%8F%E0%A4%95%E0%A5%8D%E0%A4%AF%E0%A5%82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56310bf4",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b0c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \" https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/health/%E0%A4%86%E0%A4%AF%E0%A5%81%E0%A4%B7/%E0%A4%86%E0%A4%AF%E0%A5%81%E0%A4%B7-%E0%A4%AE%E0%A4%82%E0%A4%A4%E0%A5%8D%E0%A4%B0%E0%A4%BE%E0%A4%B2%E0%A4%AF-%E0%A4%A6%E0%A5%8D%E0%A4%B5%E0%A4%BE%E0%A4%B0%E0%A4%BE-'%E0%A4%B8%E0%A4%AE%E0%A4%97%E0%A5%8D%E0%A4%B0-%E0%A4%B8%E0%A5%8D%E0%A4%B5%E0%A4%BE%E0%A4%B8%E0%A5%8D%E0%A4%A5%E0%A5%8D%E0%A4%AF-%E0%A4%94%E0%A4%B0-%E0%A4%A6%E0%A5%87%E0%A4%96%E0%A4%AD%E0%A4%BE%E0%A4%B2'-%E0%A4%95%E0%A5%87-%E0%A4%B2%E0%A4%BF%E0%A4%8F-%E0%A4%A8%E0%A4%88-%E0%A4%B8%E0%A4%BF%E0%A4%AB%E0%A4%BE%E0%A4%B0%E0%A4%BF%E0%A4%B6%E0%A5%87%E0%A4%82\"\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file1.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0518c",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a3789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/health/diseases/%E0%A4%95%E0%A5%8B%E0%A4%B0%E0%A5%8B%E0%A4%A8%E0%A4%BE-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B8-%E0%A4%86%E0%A4%B5%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%95-%E0%A4%9C%E0%A4%BE%E0%A4%A8%E0%A4%95%E0%A4%BE%E0%A4%B0%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%82-%E0%A4%94%E0%A4%B0-%E0%A4%9C%E0%A4%BE%E0%A4%97%E0%A4%B0%E0%A5%81%E0%A4%95%E0%A4%A4%E0%A4%BE/%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%AE%E0%A4%B0%E0%A5%80%E0%A4%9C%E0%A5%8B%E0%A4%82-%E0%A4%AE%E0%A5%87%E0%A4%82-%E0%A4%AE%E0%A4%BF%E0%A4%B2%E0%A4%A8%E0%A5%87-%E0%A4%B5%E0%A4%BE%E0%A4%B2%E0%A5%87-%E0%A4%AB%E0%A4%82%E0%A4%97%E0%A4%B2-%E0%A4%B8%E0%A4%82%E0%A4%95%E0%A5%8D%E0%A4%B0%E0%A4%AE%E0%A4%A3-%E0%A4%AE%E0%A5%8D%E0%A4%AF%E0%A5%82%E0%A4%95%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%AE%E0%A4%BF%E0%A4%95%E0%A5%8B%E0%A4%B8%E0%A4%BF%E0%A4%B8-%E0%A4%B8%E0%A5%87-%E0%A4%B8%E0%A5%81%E0%A4%B0%E0%A4%95%E0%A5%8D%E0%A4%B7%E0%A4%BF%E0%A4%A4-%E0%A4%B0%E0%A4%B9%E0%A5%87%E0%A4%82\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file2.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376d377",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4863a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/schemesall/%E0%A4%AA%E0%A5%8D%E0%A4%B0%E0%A4%A7%E0%A4%BE%E0%A4%A8%E0%A4%AE%E0%A4%82%E0%A4%A4%E0%A5%8D%E0%A4%B0%E0%A5%80-%E0%A4%97%E0%A4%B0%E0%A5%80%E0%A4%AC-%E0%A4%95%E0%A4%B2%E0%A5%8D%E0%A4%AF%E0%A4%BE%E0%A4%A3-%E0%A4%AF%E0%A4%BE%E0%A5%87%E0%A4%9C%E0%A4%A8%E0%A4%BE/%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%B8%E0%A5%87-%E0%A4%B2%E0%A4%A1%E0%A4%BC%E0%A4%A8%E0%A5%87-%E0%A4%B5%E0%A4%BE%E0%A4%B2%E0%A5%87-%E0%A4%B8%E0%A5%8D%E0%A4%B5%E0%A4%BE%E0%A4%B8%E0%A5%8D%E0%A4%A5%E0%A5%8D%E0%A4%AF-%E0%A4%95%E0%A4%BE%E0%A4%B0%E0%A5%8D%E0%A4%AF%E0%A4%95%E0%A4%B0%E0%A5%8D%E0%A4%A4%E0%A4%BE%E0%A4%93%E0%A4%82-%E0%A4%95%E0%A5%87-%E0%A4%B2%E0%A4%BF%E0%A4%8F-%E0%A4%AC%E0%A5%80%E0%A4%AE%E0%A4%BE-%E0%A4%AF%E0%A5%8B%E0%A4%9C%E0%A4%A8%E0%A4%BE\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "# with open('D:/AI4bharat/intern/data/hindi_file4.json', 'w', encoding='utf-8') as json_file:\n",
    "#     json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975455d2",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/health/diseases/%E0%A4%95%E0%A5%8B%E0%A4%B0%E0%A5%8B%E0%A4%A8%E0%A4%BE-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B8-%E0%A4%86%E0%A4%B5%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%95-%E0%A4%9C%E0%A4%BE%E0%A4%A8%E0%A4%95%E0%A4%BE%E0%A4%B0%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%82-%E0%A4%94%E0%A4%B0-%E0%A4%9C%E0%A4%BE%E0%A4%97%E0%A4%B0%E0%A5%81%E0%A4%95%E0%A4%A4%E0%A4%BE/%E0%A4%B8%E0%A5%87%E0%A4%82%E0%A4%B8%E0%A4%BF%E0%A4%9F-%E0%A4%B0%E0%A5%88%E0%A4%AA%E0%A4%BF%E0%A4%A1-%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%8F%E0%A4%9C%E0%A5%80-%E0%A4%95%E0%A4%BF%E0%A4%9F\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file4.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09202d9c",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "841e226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/news/%E0%A4%88%E0%A4%AA%E0%A5%80%E0%A4%8F%E0%A4%AB%E0%A4%93-%E0%A4%A6%E0%A5%8D%E0%A4%B5%E0%A4%BE%E0%A4%B0%E0%A4%BE-%E0%A4%85%E0%A4%AA%E0%A4%A8%E0%A5%87-%E0%A4%B8%E0%A4%A6%E0%A4%B8%E0%A5%8D%E0%A4%AF%E0%A5%8B%E0%A4%82-%E0%A4%95%E0%A5%8B-%E0%A4%A6%E0%A5%82%E0%A4%B8%E0%A4%B0%E0%A4%BE-%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%8F%E0%A4%A1%E0%A4%B5%E0%A4%BE%E0%A4%82%E0%A4%B8-(%E0%A4%85%E0%A4%97%E0%A5%8D%E0%A4%B0%E0%A4%BF%E0%A4%AE)-%E0%A4%B2%E0%A5%87%E0%A4%A8%E0%A5%87-%E0%A4%95%E0%A5%80-%E0%A4%85%E0%A4%A8%E0%A5%81%E0%A4%AE%E0%A4%A4%E0%A4%BF\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file5.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3897d",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c4fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/health/diseases/%E0%A4%95%E0%A5%8B%E0%A4%B0%E0%A5%8B%E0%A4%A8%E0%A4%BE-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B8-%E0%A4%86%E0%A4%B5%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%95-%E0%A4%9C%E0%A4%BE%E0%A4%A8%E0%A4%95%E0%A4%BE%E0%A4%B0%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%82-%E0%A4%94%E0%A4%B0-%E0%A4%9C%E0%A4%BE%E0%A4%97%E0%A4%B0%E0%A5%81%E0%A4%95%E0%A4%A4%E0%A4%BE/%E0%A4%AA%E0%A4%BF%E0%A4%82%E0%A4%AA%E0%A4%B0%E0%A5%80-%E0%A4%9A%E0%A4%BF%E0%A4%82%E0%A4%9A%E0%A4%B5%E0%A4%A1-%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%B5%E0%A4%BE%E0%A4%B0-%E0%A4%B0%E0%A5%82%E0%A4%AE-%E0%A4%AE%E0%A5%87%E0%A4%82-%E0%A4%A4%E0%A4%95%E0%A4%A8%E0%A5%80%E0%A4%95-%E0%A4%95%E0%A4%BE-%E0%A4%B5%E0%A5%8D%E0%A4%AF%E0%A4%BE%E0%A4%AA%E0%A4%95-%E0%A4%89%E0%A4%AA%E0%A4%AF%E0%A5%8B%E0%A4%97\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file6.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e99847",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51f94d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/health/diseases/%E0%A4%A4%E0%A5%8D%E0%A4%B5%E0%A4%9A%E0%A4%BE-%E0%A4%B8%E0%A4%82%E0%A4%AC%E0%A4%82%E0%A4%A7%E0%A5%80-%E0%A4%AC%E0%A5%80%E0%A4%AE%E0%A4%BE%E0%A4%B0%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%82/%E0%A4%AE%E0%A5%8D%E0%A4%AF%E0%A5%82%E0%A4%95%E0%A5%8B%E0%A4%B0%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95%E0%A5%8B%E0%A4%B8%E0%A4%BF%E0%A4%B8\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file7.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b49c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3999e37",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43ff49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/news/%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%B8%E0%A5%87-%E0%A4%B2%E0%A4%A1%E0%A4%BC%E0%A4%A8%E0%A5%87-%E0%A4%B5%E0%A4%BE%E0%A4%B2%E0%A5%87-%E0%A4%B8%E0%A5%8D%E0%A4%B5%E0%A4%BE%E0%A4%B8%E0%A5%8D%E0%A4%A5%E0%A5%8D%E0%A4%AF-%E0%A4%95%E0%A4%B0%E0%A5%8D%E0%A4%AE%E0%A4%BF%E0%A4%AF%E0%A5%8B%E0%A4%82-%E0%A4%95%E0%A5%87-%E0%A4%B2%E0%A4%BF%E0%A4%8F-%E0%A4%AC%E0%A5%80%E0%A4%AE%E0%A4%BE-%E0%A4%AF%E0%A5%8B%E0%A4%9C%E0%A4%A8%E0%A4%BE-%E0%A4%85%E0%A4%97%E0%A4%B2%E0%A5%87-180-%E0%A4%A6%E0%A4%BF%E0%A4%A8%E0%A5%8B%E0%A4%82-%E0%A4%95%E0%A5%87-%E0%A4%B2%E0%A4%BF%E0%A4%8F-%E0%A4%AC%E0%A4%A2%E0%A4%BC%E0%A4%BE%E0%A4%88-%E0%A4%97%E0%A4%88\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file8.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9862a",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce1c271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/health/diseases/%E0%A4%95%E0%A5%8B%E0%A4%B0%E0%A5%8B%E0%A4%A8%E0%A4%BE-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B8-%E0%A4%86%E0%A4%B5%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%95-%E0%A4%9C%E0%A4%BE%E0%A4%A8%E0%A4%95%E0%A4%BE%E0%A4%B0%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%82-%E0%A4%94%E0%A4%B0-%E0%A4%9C%E0%A4%BE%E0%A4%97%E0%A4%B0%E0%A5%81%E0%A4%95%E0%A4%A4%E0%A4%BE/%E0%A4%86%E0%A4%AF%E0%A5%81%E0%A4%B7-%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%95%E0%A4%BE%E0%A4%89%E0%A4%82%E0%A4%B8%E0%A4%B2%E0%A4%BF%E0%A4%82%E0%A4%97-%E0%A4%B9%E0%A5%87%E0%A4%B2%E0%A5%8D%E0%A4%AA%E0%A4%B2%E0%A4%BE%E0%A4%87%E0%A4%A8\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file9.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d314e77a",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d5d0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests  # used to get http from any website\n",
    "from bs4 import BeautifulSoup  # we get the data of html page in WELL MANNERED FORMAT\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "s = Service('D:/software/selenium/chromedriver-win64/chromedriver.exe')\n",
    "\n",
    "driver = webdriver.Chrome(service=s,options =options)\n",
    "url = \"https://xn--j2bd4cyah0f.xn--11by0av0at5becfj.xn--h2brj9c/health/diseases/%E0%A4%95%E0%A5%8B%E0%A4%B0%E0%A5%8B%E0%A4%A8%E0%A4%BE-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B8-%E0%A4%86%E0%A4%B5%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%95-%E0%A4%9C%E0%A4%BE%E0%A4%A8%E0%A4%95%E0%A4%BE%E0%A4%B0%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%82-%E0%A4%94%E0%A4%B0-%E0%A4%9C%E0%A4%BE%E0%A4%97%E0%A4%B0%E0%A5%81%E0%A4%95%E0%A4%A4%E0%A4%BE/%E0%A4%95%E0%A5%8B%E0%A4%B5%E0%A4%BF%E0%A4%A1-19-%E0%A4%95%E0%A5%87-%E0%A4%96%E0%A4%BF%E0%A4%B2%E0%A4%BE%E0%A4%AB-%E0%A4%B2%E0%A4%A1%E0%A4%BE%E0%A4%88-%E0%A4%AE%E0%A5%87%E0%A4%82-%E0%A4%85%E0%A4%9C%E0%A4%AE%E0%A5%87%E0%A4%B0-%E0%A4%B8%E0%A5%8D%E0%A4%AE%E0%A4%BE%E0%A4%B0%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A4%BF%E0%A4%9F%E0%A5%80-%E0%A4%95%E0%A4%BE-%E0%A4%B5%E0%A5%89%E0%A4%B0-%E0%A4%B0%E0%A5%82%E0%A4%AE-%E0%A4%95%E0%A5%80-%E0%A4%AE%E0%A4%B9%E0%A4%A4%E0%A5%8D%E0%A4%B5%E0%A4%AA%E0%A5%82%E0%A4%B0%E0%A5%8D%E0%A4%A3-%E0%A4%AD%E0%A5%82%E0%A4%AE%E0%A4%BF%E0%A4%95%E0%A4%BE\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "heading = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[1]/div[2]/div[1]/h3')\n",
    "para = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[3]/div/div[2]/div[2]/div[2]/div[1]/div[3]/div/div/div/div[2]/div/div')\n",
    "\n",
    "# print(para.text)\n",
    "# print(heading.text)\n",
    "\n",
    "content = heading.text.strip() + '/n' + para.text.strip()\n",
    "# print(content)\n",
    "\n",
    "# Create a dictionary to store the scraped data\n",
    "article_data = {\n",
    "    \"text\": content,\n",
    "    \"source\": \"vikaspedia\",  # Replace with the actual source name\n",
    "    \"url\": url,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "article_json = json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('D:/AI4bharat/intern/data/hindi_file10.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(article_json)\n",
    "\n",
    "# Print or save the JSON data\n",
    "\n",
    "# print(article_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dacf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74709221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f250a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53642a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de0617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
